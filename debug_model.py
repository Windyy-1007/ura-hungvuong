"""
Debug Model Predictions
======================

This script debugs why the model is predicting all zeros.
"""

import pandas as pd
import numpy as np
import joblib
import sys
from pathlib import Path

def debug_model_predictions():
    """Debug the prediction process step by step"""
    
    print("ğŸ” DEBUGGING MODEL PREDICTIONS")
    print("=" * 50)
    
    # Load model and preprocessing
    model_path = Path("models/multi_output_medical_model_20250910_165814")
    
    print("ğŸ“ Loading model components...")
    model = joblib.load(model_path / "multi_output_medical_model.joblib")
    preprocessing = joblib.load(model_path / "preprocessing.joblib")
    
    print(f"âœ… Model loaded: {type(model)}")
    print(f"âœ… Preprocessing loaded: {len(preprocessing)} components")
    
    # Load original training data to understand distribution
    print("\nğŸ“Š Loading original training data...")
    df = pd.read_csv("data/dataset_long_format_normalized_labeled.csv")
    
    # Get target distributions
    target_columns = [col for col in df.columns if col.startswith('Káº¿ hoáº¡ch (xá»­ trÃ­)_')]
    print(f"\nğŸ¯ Target Label Distributions:")
    print("-" * 40)
    
    target_stats = {}
    for col in target_columns:
        if col in df.columns:
            value_counts = df[col].value_counts()
            if len(value_counts) >= 2:
                pos_ratio = value_counts.get(1, 0) / len(df) * 100
                target_stats[col] = {
                    'total_samples': len(df),
                    'positive_cases': value_counts.get(1, 0),
                    'positive_ratio': pos_ratio
                }
                print(f"{col.replace('Káº¿ hoáº¡ch (xá»­ trÃ­)_', ''):<25} {value_counts.get(1, 0):>4}/{len(df):<4} ({pos_ratio:.1f}%)")
    
    # Create a test case that should definitely be positive
    print(f"\nğŸ§ª Creating extreme test case...")
    extreme_case = {
        "NÄƒm sinh": 1990,
        "Para (Ä‘iá»n 4 sá»‘)": 0,
        "Tiá»n cÄƒn bá»‡nh lÃ½": "TÄƒng huyáº¿t Ã¡p",
        "Khá»Ÿi phÃ¡t chuyá»ƒn dáº¡ (1: CÃ³, 0: KhÃ´ng)": 1.0,
        "hour": 20,
        "Báº¡n Ä‘á»“ng hÃ nh (1: CÃ³, 0: KhÃ´ng)": 0.0,
        "ÄÃ¡nh giÃ¡ má»©c Ä‘á»™ Ä‘au (VAS) (Äiá»n sá»‘ nguyÃªn)": 10.0,  # Maximum pain
        "NÆ°á»›c uá»‘ng vÃ o (1: CÃ³, 0: KhÃ´ng)": 0.0,
        "Ä‚n": 0.0,
        "Máº¡ch (nháº­p sá»‘ nguyÃªn)": 150.0,  # Severe tachycardia
        "HA tÃ¢m thu (nháº­p sá»‘ nguyÃªn)": 200.0,  # Severe hypertension
        "HA tÃ¢m trÆ°Æ¡ng (nháº­p sá»‘ nguyÃªn)": 120.0,
        "Nhiá»‡t Ä‘á»™ (nháº­p sá»‘ nguyÃªn)": 40.0,  # High fever
        "TT cÆ¡ báº£n (nháº­p sá»‘ nguyÃªn)": 50.0,  # Severe fetal bradycardia
    }
    
    # Debug preprocessing step by step
    print(f"\nğŸ”§ DEBUGGING PREPROCESSING")
    print("-" * 40)
    
    # Step 1: Create DataFrame
    test_df = pd.DataFrame([extreme_case])
    print(f"1. Test data shape: {test_df.shape}")
    print(f"   Sample values: Pulse={extreme_case['Máº¡ch (nháº­p sá»‘ nguyÃªn)']}, BP={extreme_case['HA tÃ¢m thu (nháº­p sá»‘ nguyÃªn)']}")
    
    # Step 2: Add missing feature columns
    feature_columns = preprocessing['feature_columns']
    print(f"2. Expected features: {len(feature_columns)}")
    
    for col in feature_columns:
        if col not in test_df.columns:
            test_df[col] = np.nan
    
    test_df = test_df[feature_columns]
    print(f"   After adding missing columns: {test_df.shape}")
    
    # Step 3: Handle missing values
    print(f"3. Handling missing values...")
    missing_before = test_df.isna().sum().sum()
    
    for col in test_df.columns:
        if test_df[col].dtype in ['object', 'string']:
            test_df[col].fillna('Unknown', inplace=True)
        else:
            test_df[col].fillna(test_df[col].median() if not test_df[col].isna().all() else 0, inplace=True)
    
    missing_after = test_df.isna().sum().sum()
    print(f"   Missing values: {missing_before} -> {missing_after}")
    
    # Step 4: Apply label encoders
    print(f"4. Applying label encoders...")
    label_encoders = preprocessing['label_encoders']
    print(f"   Available encoders: {len(label_encoders)}")
    
    # Check for problematic encoders
    numeric_cols_with_encoders = []
    for col, encoder in label_encoders.items():
        if col in test_df.columns:
            original_dtype = test_df[col].dtype
            print(f"   Encoding {col}: dtype={original_dtype}, classes={len(encoder.classes_)}")
            
            # Check if this is incorrectly encoding a numeric column
            if original_dtype in ['int64', 'float64']:
                numeric_cols_with_encoders.append(col)
                print(f"   âš ï¸  WARNING: Encoding numeric column {col}!")
            
            test_df[col] = test_df[col].astype(str)
            known_labels = set(encoder.classes_)
            unknown_mask = ~test_df[col].isin(known_labels)
            if unknown_mask.any():
                print(f"   âš ï¸  Unknown values in {col}, using default: {encoder.classes_[0]}")
                test_df.loc[unknown_mask, col] = encoder.classes_[0]
            test_df[col] = encoder.transform(test_df[col])
    
    if numeric_cols_with_encoders:
        print(f"\nâŒ PROBLEM IDENTIFIED: {len(numeric_cols_with_encoders)} numeric columns being encoded!")
        print(f"   Problematic columns: {numeric_cols_with_encoders[:5]}")
    
    # Step 5: Make prediction
    print(f"\n5. Making prediction...")
    print(f"   Preprocessed data shape: {test_df.shape}")
    print(f"   Sample preprocessed values: {test_df.iloc[0, :5].values}")
    
    # Get raw model output
    raw_prediction = model.predict(test_df)
    prediction_proba = model.predict_proba(test_df)
    
    print(f"   Raw prediction shape: {raw_prediction.shape}")
    print(f"   Raw prediction values: {raw_prediction[0]}")
    print(f"   Any positive predictions: {np.any(raw_prediction[0] == 1)}")
    
    # Check prediction probabilities
    print(f"\nğŸ“Š PREDICTION PROBABILITIES:")
    print("-" * 40)
    
    target_names = preprocessing.get('target_names', [f"Target_{i}" for i in range(len(raw_prediction[0]))])
    
    for i, (target, pred, proba_dist) in enumerate(zip(target_names, raw_prediction[0], prediction_proba)):
        if hasattr(proba_dist, '__iter__') and len(proba_dist) > 1:
            proba_positive = proba_dist[0][1] if len(proba_dist[0]) > 1 else 0.0
        else:
            proba_positive = 0.0
        
        status = "ğŸ”´" if pred == 1 else "âšª"
        print(f"   {status} {target:<25} Pred={pred} P(1)={proba_positive:.3f}")
    
    # Check against some actual positive cases from training data
    print(f"\nğŸ” COMPARING WITH ACTUAL POSITIVE CASES")
    print("-" * 50)
    
    # Find a case with positive labels in the original data
    for target_col in target_columns[:3]:  # Check first 3 targets
        if target_col in df.columns:
            positive_cases = df[df[target_col] == 1]
            if len(positive_cases) > 0:
                print(f"\nğŸ“‹ Analyzing actual positive case for {target_col.replace('Káº¿ hoáº¡ch (xá»­ trÃ­)_', '')}:")
                
                # Get the first positive case
                positive_case = positive_cases.iloc[0]
                
                # Show key features
                key_features = ['Máº¡ch (nháº­p sá»‘ nguyÃªn)', 'HA tÃ¢m thu (nháº­p sá»‘ nguyÃªn)', 'TT cÆ¡ báº£n (nháº­p sá»‘ nguyÃªn)', 'ÄÃ¡nh giÃ¡ má»©c Ä‘á»™ Ä‘au (VAS) (Äiá»n sá»‘ nguyÃªn)']
                print(f"   Key features from positive case:")
                for feature in key_features:
                    if feature in positive_case:
                        print(f"     {feature}: {positive_case[feature]}")
                
                break
    
    print(f"\nğŸ” DIAGNOSIS:")
    print("=" * 50)
    if numeric_cols_with_encoders:
        print("âŒ MAJOR ISSUE: Numeric columns are being incorrectly label-encoded")
        print("   This corrupts the feature values and makes predictions unreliable")
        print("   Solution: Fix preprocessing to only encode categorical columns")
    
    if not np.any(raw_prediction[0] == 1):
        print("âŒ MODEL ISSUE: No positive predictions even for extreme case")
        print("   This suggests model threshold issues or training data problems")
    
    print("\nğŸ’¡ RECOMMENDED FIXES:")
    print("1. Fix preprocessing to preserve numeric columns")
    print("2. Retrain model with correct preprocessing")
    print("3. Verify training data has sufficient positive examples")

if __name__ == "__main__":
    debug_model_predictions()